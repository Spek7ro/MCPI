P_Valor = p_val,
Accuracy = accuracy_val,
stringsAsFactors = FALSE
))
}
}
formulita <- as.formula("classification ~ age")
modelo <- glm(formula = formulita, data = datos_cancer, family = "binomial")
# Obtener las prediccines sobre el conjunto de datos
predicciones <- predict(modelo, newdata = datos_cancer, type = "response")
predicciones
# Crear la tabla de comparaciones entre lo real y lo predicho
tablita <- data.frame(Original = datos_cancer$classification,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial los datos de tablita (prediccionesModelo)
tablita$prediccionesModelo[tablita$prediccionesModelo < 0.5] <- 0
tablita$prediccionesModelo[tablita$prediccionesModelo >= 0.5] <- 1
# Calcular las metricas (Accuracy)
accuracy <- sum(tablita$Original == tablita$prediccionesModelo)/nrow(tablita)
accuracy
summary(modelo)
# Obtener: Desviacion estandar, Varianza, Rango Dinamico, p-valor y Accuracy
# De cada variable independinte
# Recorrer cada variable con un ciclo for
for (var in variables) {
# Verificar si la variable es numérica (para evitar errores con texto o factores)
if (is.numeric(datos_cancer[[var]])) {
# Calcular estadísticas básicas
sd_val <- sd(datos_cancer[[var]])
var_val <- var(datos_cancer[[var]])
rango_val <- max(datos_cancer[[var]], na.rm = TRUE) - min(datos_cancer[[var]], na.rm = TRUE)
# -------- Modelo logístico univariado -------- ML
p_val <- NA
accuracy_val <- NA
try({
formulita <- as.formula(paste("classification ~", var))
modelo <- glm(formula = formulita, data = datos_cancer, family = "binomial")
resumen <- summary(modelo)
# Verificar si hay coeficiente aparte del intercepto
if (nrow(coef(resumen)) >= 2) {
p_val <- coef(resumen)[2, 4]  # p-valor de la variable
}
# Calcular predicciones y accuracy
predicciones <- ifelse(predict(modelo, type = "response") > 0.5, 1, 0)
accuracy_val <- mean(predicciones == datos_cancer$classification, na.rm = TRUE)
}, silent = TRUE)
# Agregar resultados al data.frame
resultados <- rbind(resultados, data.frame(
Variable = var,
Desviacion_Estandar = sd_val,
Varianza = var_val,
Rango = rango_val,
P_Valor = p_val,
Accuracy = accuracy_val,
stringsAsFactors = FALSE
))
}
}
# Crear un data frame vacío donde guardaremos los resultados
install.packages("gt")
library(gt)
library(dplyr)
### Tabla de resultados:
gt(resultados)
resultados %>%
gt()
data %>%
gt() %>%
tab_header(title = md("Analisi **Univariado**"),
subtitle = md("Cancer de mama"))
resultados %>%
gt() %>%
tab_header(title = md("Analisi **Univariado**"),
subtitle = md("Cancer de mama"))
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
print(resultados, digits = 4)
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama")),
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
resultados %>%
gt() %>%
tab_spanner(
label = "Estadísticos",
columns = c(Desviacion_Estandar, Varianza, Rango)) %>%
tab_spanner(
label = "ML",
columns = c(P_Valor, Accuracy)
)
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
resultados %>%
gt() %>%
tab_spanner(
label = "Estadísticos",
columns = c(Desviacion_Estandar, Varianza, Rango)) %>%
tab_spanner(
label = "ML",
columns = c(P_Valor, Accuracy)
)
resultados %>%
gt() %>%
tab_spanner(
label = "**Estadísticos**",
columns = c(Desviacion_Estandar, Varianza, Rango)) %>%
tab_spanner(
label = "**ML**",
columns = c(P_Valor, Accuracy)
)
resultados %>%
gt() %>%
tab_header(title = md("**Análisis univariado**"),
subtitle = md("Cáncer de mama"))
install.packages("gtsummary")
### Otro tipo de tabla
library(gtsummary)
formulita <- as.formula("classification ~ age")
modelo <- glm(formula = formulita, data = datos_cancer, family = "binomial")
summary(modelo)
# generate table
model %>%
tbl_regression()
# generate table
modelo %>%
tbl_regression()
formulita <- as.formula("classification ~ age + t_energ")
modelo <- glm(formula = formulita, data = datos_cancer, family = "binomial")
summary(modelo)
# generate table
modelo %>%
tbl_regression()
install.packages("caret")
library(caret)
# Cragar datos
datos <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv")
View(datos)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
DatosTitanic
colnames(DatosTitanic)
class(DatosTitanic$Sexo)
# Limpiar el dataset
sum(is.na(datos$Id))
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad))
datos_limpios <- DatosTitanic[is.na(DatosTitanic$Edad) == FALSE]
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- datos[!is.na(datos$Edad), ]
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic!is.na(datos$Edad), ]
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic!is.na(DatosTitanic$Edad), ]
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# Validacion Cruzada
createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
View(datos_limpios)
# Validacion Cruzada
indices = createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
# Validacion Cruzada K = 1
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ]
View(datos_Fold_Entrenaminto)
View(datos_Fold_Prueba)
# Entrenamintos Modelos
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
View(tablitaX)
# Binarizar pero de forma vectorial:
tablita$prediccionesIA[tablita$prediccionesIA < 0.5] <- 0
# Binarizar pero de forma vectorial:
tablitaX$prediccionesIA[tablita$prediccionesIA < 0.5] <- 0
tablitaX$prediccionesIA[tablita$prediccionesIA >= 0.5] <- 1
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
View(tablitaX)
######## Ahora para VALIDACION ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
######################
# Validacion Cruzada K = 2
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold2, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold2, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
######## Ahora para VALIDACION K =1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7605042
######################
# Validacion Cruzada K = 3
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold3, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold3, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7941176
######## Ahora para VALIDACION K = 3 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7521008
DatosTitanic_SinLimpiar <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic_SinLimpiar)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
View(DatosTitanic_SinLimpiar)
View(DatosTitanic_SinLimpiar)
View(DatosTitanic_SinLimpiar)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# crear la particiones para TRAIN y TRAINING K = 3
indices = createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
# Validacion Cruzada K = 1
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
library(caret)
# Limpiar el dataset
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# Crear las particiones para K = 3
set.seed(123)
indices <- createFolds(y = datos_limpios$Vivio, k = 3, returnTrain = TRUE, list = TRUE)
# Función para calcular las métricas
calcular_metricas <- function(original, predicciones) {
cm <- table(Original = original, Prediccion = predicciones)
print(cm)
# Matriz de confusion
TN <- cm[1,1]
FP <- cm[1,2]
FN <- cm[2,1]
TP <- cm[2,2]
# Métricas
accuracy <- (TP + TN) / sum(cm)
sensibilidad <- TP / (TP + FN)
especificidad <- TN / (TN + FP)
return(list(Accuracy = accuracy,
Sensibilidad = sensibilidad,
Especificidad = especificidad))
}
# Validación cruzada para cada FOLD
for (i in 1:3) {
cat("\n================ FOLD", i, "================\n")
# Crear conjuntos de entrenamiento y prueba
datos_Fold_Entrenaminto <- datos_limpios[indices[[i]], ]
datos_Fold_Prueba <- datos_limpios[-indices[[i]], ]
# Entrenar el modelo
modeloX <- glm(Vivio ~ Sexo + Edad, data = datos_Fold_Entrenaminto, family = "binomial")
# ---- TRAIN ----
pred_train <- predict(modeloX, newdata = datos_Fold_Entrenaminto, type = "response")
pred_train_bin <- ifelse(pred_train >= 0.5, 1, 0)
metricas_train <- calcular_metricas(datos_Fold_Entrenaminto$Vivio, pred_train_bin)
cat("TRAIN:\n")
print(metricas_train)
# ---- TEST ----
pred_test <- predict(modeloX, newdata = datos_Fold_Prueba, type = "response")
pred_test_bin <- ifelse(pred_test >= 0.5, 1, 0)
metricas_test <- calcular_metricas(datos_Fold_Prueba$Vivio, pred_test_bin)
cat("TEST:\n")
print(metricas_test)
# ---- Guardar tablitas para Excel ----
tablita_train <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
PrediccionIA = pred_train_bin)
tablita_test <- data.frame(Original = datos_Fold_Prueba$Vivio,
PrediccionIA = pred_test_bin)
write.csv(tablita_train, paste0("Fold", i, "_Train.csv"), row.names = FALSE)
write.csv(tablita_test, paste0("Fold", i, "_Test.csv"), row.names = FALSE)
}
library(openxlsx)
install.packages("openxlsx")
library(openxlsx)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
library(caret)
library(openxlsx)
# Eliminar valores NA de Edad
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# Crear particiones para K = 3
set.seed(123)
indices <- createFolds(y = datos_limpios$Vivio, k = 3, returnTrain = TRUE, list = TRUE)
# Función auxiliar para crear la tablita con TP, TN, FP, FN
crear_tablita <- function(original, prediccion) {
df <- data.frame(ValorOriginal = original, Predicciones = prediccion)
df$TP <- ifelse(df$ValorOriginal == 1 & df$Predicciones == 1, 1, 0)
df$TN <- ifelse(df$ValorOriginal == 0 & df$Predicciones == 0, 1, 0)
df$FP <- ifelse(df$ValorOriginal == 0 & df$Predicciones == 1, 1, 0)
df$FN <- ifelse(df$ValorOriginal == 1 & df$Predicciones == 0, 1, 0)
# Totales
TP <- sum(df$TP)
TN <- sum(df$TN)
FP <- sum(df$FP)
FN <- sum(df$FN)
sensibilidad <- round(TP / (TP + FN), 2)
especificidad <- round(TN / (TN + FP), 2)
# Fila de suma
fila_suma <- data.frame(ValorOriginal = "SUMA=", Predicciones = "",
TP = TP, TN = TN, FP = FP, FN = FN)
df_final <- rbind(df, fila_suma)
# Fila de métricas
fila_sens <- data.frame(ValorOriginal = "SENSITIVITY (TP/(TP+FN))", Predicciones = "",
TP = sensibilidad, TN = "", FP = "", FN = paste0(sensibilidad*100, "%"))
fila_esp <- data.frame(ValorOriginal = "SPECIFICITY (TN/(FP+TN))", Predicciones = "",
TP = especificidad, TN = "", FP = "", FN = paste0(especificidad*100, "%"))
df_final <- rbind(df_final, fila_sens, fila_esp)
return(df_final)
}
# Crear archivo Excel
wb <- createWorkbook()
# ---- Iterar por cada FOLD ----
for (i in 1:3) {
# Datos
datos_train <- datos_limpios[indices[[i]], ]
datos_test <- datos_limpios[-indices[[i]], ]
# Modelo
modelo <- glm(Vivio ~ Sexo + Edad, data = datos_train, family = "binomial")
# Predicciones binarizadas
pred_train <- ifelse(predict(modelo, newdata = datos_train, type = "response") >= 0.5, 1, 0)
pred_test <- ifelse(predict(modelo, newdata = datos_test, type = "response") >= 0.5, 1, 0)
# Crear tablitas
tablita_train <- crear_tablita(datos_train$Vivio, pred_train)
tablita_test <- crear_tablita(datos_test$Vivio, pred_test)
# Guardar cada una como hoja
addWorksheet(wb, paste0("Fold", i, "_TRAIN"))
addWorksheet(wb, paste0("Fold", i, "_TEST"))
writeData(wb, sheet = paste0("Fold", i, "_TRAIN"), tablita_train)
writeData(wb, sheet = paste0("Fold", i, "_TEST"), tablita_test)
}
# Guardar Excel final
saveWorkbook(wb, "Resultados_Titanic_Folds.xlsx", overwrite = TRUE)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
indices = createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
# Validacion Cruzada K = 1
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7605042
library(pROC)
mi_curvaz <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels = c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
mi_curvaz <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
### Area bajo la curva
mi_curva$auc
mi_curva
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret="threshold")
valores$threshold
