accuracy
##### Validacion Cruzada y metricas para validacion de K = 1 ####
### Modelo con 5 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 1: Grafica ROC - Prueba K=3")
##### Validacion Cruzada y metricas para validacion de K = 1 ####
### Modelo con 5 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 2: Grafica ROC - Prueba K=3")
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 2: Grafica ROC - Prueba K=1")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para entrenaimnto K = 2 ####
### Modelo con 5 variables
datos_Fold_Entrenaminto <- datos_cancer[indices$Fold2, ]
datos_Fold_Prueba <- datos_cancer[-indices$Fold2, ]
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev + i_skewness + s_area,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Predicciones
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$classification,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 2: Grafica ROC -  Entrenamiento K=2")
### Area bajo la curva
mi_curva$auc
#### Obtenemos los valores de Threshold (umbral binarizacion) y metricas
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para validacion de K = 2 ####
### Modelo con 5 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 2: Grafica ROC - Prueba K=2")
#AUC
mi_curva$auc
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
##### Validacion Cruzada y metricas para validacion de K = 2 ####
### Modelo con 5 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 2: Grafica ROC - Prueba K=2")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
### Validacion Cruzada y metricas para entrenaminto K = 3 ####
### Modelo con 5 variables
datos_Fold_Entrenaminto <- datos_cancer[indices$Fold3, ]
datos_Fold_Prueba <- datos_cancer[-indices$Fold3, ]
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev + i_skewness + s_area,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Predicciones
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$classification,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 2: Grafica ROC -  Entrenamiento K=3")
### Area bajo la curva
mi_curva$auc
#### Obtenemos los valores de Threshold (umbral binarizacion) y metricas
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para validacion de K = 3 ####
### Modelo con 5 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 2: Grafica ROC - Prueba K=3")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
library(caret)
library(pROC)
# 1. Cargar datos
datos_cancer <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/bcdr_d01_features.csv")
# 2. limpiar los datos
# vamos a quitar la columna density que contiene Na´S
sum(is.na(datos_cancer$density))
# paso 1: obtener el nombre y número (posicion) de columnas
colnames(datos_cancer) # me regresa el nombre y la posicion de las columnas
# paso 2: quitar la columna 15 density (operacion vectorial)
# datos_cancer <- datos_cancer[reglones(s), columnas(s)]
datos_cancer <- datos_cancer[ , -15] # todas menos la 15
# la columna classification tienen espacios
datos_cancer$classification
# vamos a convertir Malign -> 1 y Benign -> 0
# datos_cancer$classification[cuales reglones]
datos_cancer$classification[datos_cancer$classification == " Malign "] <- 1
datos_cancer$classification[datos_cancer$classification == " Benign "] <- 0
class(datos_cancer$classification)
# cambiar la columna classification de caracter a numero
datos_cancer$classification <- as.numeric(datos_cancer$classification)
class(datos_cancer$classification)
# crear la particiones para TRAIN y TRAINING K = 3
indices = createFolds(y = datos_cancer$classification, k = 3,
returnTrain = TRUE,
list = TRUE)
# ------------------------------ Modelo 3 ------------------------------
##### Validacion Cruzada y metricas para entrenamiento K = 1 ####
### Modelo con 7 variables
colnames(datos_Fold_Prueba)
# ------------------------------ Modelo 3 ------------------------------
##### Validacion Cruzada y metricas para entrenamiento K = 1 ####
### Modelo con 7 variables
colnames(datos_cancer)
View(datos_cancer)
# ------------------------------ Modelo 3 ------------------------------
##### Validacion Cruzada y metricas para entrenamiento K = 1 ####
### Modelo con 7 variables
datos_Fold_Entrenaminto <- datos_cancer[indices$Fold1, ]
datos_Fold_Prueba <- datos_cancer[-indices$Fold1, ]
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev
+ i_skewness + s_area + s_circularity + t_energ
data = datos_Fold_Entrenaminto,
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev
+ i_skewness + s_area + s_circularity + t_energ,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Predicciones
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$classification,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 1: Grafica ROC -  Entrenamiento K=3")
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 3: Grafica ROC -  Entrenamiento K=1")
### Area bajo la curva
mi_curva$auc
#### Obtenemos los valores de Threshold (umbral binarizacion) y metricas
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para validacion de K = 1 ####
### Modelo con 7 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 3: Grafica ROC - Prueba K=1")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para entrenamiento K = 2 ####
### Modelo con 7 variables
datos_Fold_Entrenaminto <- datos_cancer[indices$Fold2, ]
datos_Fold_Prueba <- datos_cancer[-indices$Fold2, ]
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev
+ i_skewness + s_area + s_circularity + t_energ,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Predicciones
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$classification,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 3: Grafica ROC -  Entrenamiento K=2")
### Area bajo la curva
mi_curva$auc
#### Obtenemos los valores de Threshold (umbral binarizacion) y metricas
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para validacion de K = 2 ####
### Modelo con 7 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 3: Grafica ROC - Prueba K=2")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
### Validacion Cruzada y metricas para entrenamiento K = 3 ####
### Modelo con 7 variables
datos_Fold_Entrenaminto <- datos_cancer[indices$Fold3, ]
datos_Fold_Prueba <- datos_cancer[-indices$Fold3, ]
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(classification ~ age + i_mean + i_std_dev
+ i_skewness + s_area + s_circularity + t_energ,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Predicciones
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$classification,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Modelo 3: Grafica ROC -  Entrenamiento K=3")
### Area bajo la curva
mi_curva$auc
#### Obtenemos los valores de Threshold (umbral binarizacion) y metricas
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
##### Validacion Cruzada y metricas para validacion de K = 3 ####
### Modelo con 7 variables
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba, type="response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$classification,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Modelo 3: Grafica ROC - Prueba K=3")
#AUC
mi_curva$auc
valores <- coords(mi_curva,"best",ret=c("threshold","specificity", "sensitivity"))
valores
#Binarizar
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo<valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo>=valores$threshold] <- 1
# Calcular el accuracy de validacion
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy
datos <- read.delim("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/caballos.txt", stringsAsFactors=TRUE)
View(datos)
datos <- read.delim("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/caballos.txt", stringsAsFactors=TRUE)
# Para SVM la calse debe ser factor
class(datos$animal)
# Vamos a convertir la columna de "animal" de entero a FACTOR
datos$animal <- as.factor(datos$animal)
class(datos$animal)
# Mostramos los datos solo como visualizacion
plot(datos[ , c(1,2)], col=datos$animal, pch=19)
# Vamos a crear el modelo SVM
library(e1071)
View(datos)
# modelo
modelo_svm <- svm(animal ~ Height + Weight, data = datos,
type="C-classification",
kernel="linear",
scale = FALSE)
summary(modelo_svm)
View(datos)
View(datos)
## 100% Didactico #####
# Donde estan los soportes (Soft margins)?
points(datos[modelo_svm$index, c(1,2)], col="red", cex=3, lwd=2)
## 100% Didactico #####
# Donde estan los soportes (Soft margins)?
points(datos[modelo_svm$index, c(1,2)], col="green", cex=3, lwd=2)
# Dibujar el hiperplano (enalogo a los betas de una reg)
w <- t(modelo_svm$coefs)%*%modelo_svm
# Dibujar el hiperplano (enalogo a los betas de una reg)
w <- t(modelo_svm$coefs)%*%modelo_svm$SV
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="purple", lty=2)
b <- (modelo_svm$rho)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="purple", lty=2)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="purple", lty=2)
## 100% Didactico #####
# Donde estan los soportes (Soft margins)?
points(datos[modelo_svm$index, c(1,2)], col="green", cex=3, lwd=2)
# Dibujar el hiperplano (enalogo a los betas de una reg)
w <- t(modelo_svm$coefs)%*%modelo_svm$SV
b <- (modelo_svm$rho)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="purple", lty=2)
# Mostramos los datos solo como visualizacion
plot(datos[ , c(1,2)], col=datos$animal, pch=19)
# Vamos a crear el modelo SVM
library(e1071)
# modelo
modelo_svm <- svm(animal ~ Height + Weight, data = datos,
type="C-classification",
kernel="linear",
scale = FALSE)
summary(modelo_svm)
## 100% Didactico #####
# Donde estan los soportes (Soft margins)?
points(datos[modelo_svm$index, c(1,2)], col="green", cex=3, lwd=2)
# Dibujar el hiperplano (enalogo a los betas de una reg)
w <- t(modelo_svm$coefs)%*%modelo_svm$SV
b <- (modelo_svm$rho)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="purple", lty=2)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green", lty=2)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green", lty=2)
###
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green",
lty=2)
### Vamos a probar con nuevos datos
nuevos_datos <- data.frame(Height=(67, 120, 100),
### Vamos a probar con nuevos datos
nuevos_datos <- data.frame(Height=(67, 120, 100),
### Vamos a probar con nuevos datos
nuevos_datos <- data.frame(Height=c(67, 120, 100),
Weigt=c(100, 190, 100),
)
### Vamos a probar con nuevos datos
nuevos_datos <- data.frame(Height=c(67, 120, 100),
Weigt=c(100, 190, 100)
)
View(nuevos_datos)
# Vamos a agregar a la grafica los nuevos datos
# Para clasificarlos
points(nuevos_datos[1, ], col="green", pch=11)
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[, c(1,2)], col=datos$animal,pch=19,
xlim=c(0, 180),
ylim=C(80,200))
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[ ,c(1,2)], col=datos$animal,pch=19,
xlim=c(0, 180),
ylim=C(80,200))
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green",
lty=2)
par()
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green",
lty=2)
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[ ,c(1,2)], col=datos$animal,pch=19,
xlim=c(0, 180),
ylim=C(80,200))
# Vamos a agregar a la grafica los nuevos datos
# Para clasificarlos
points(nuevos_datos[1, ], col="green", pch=11) # primer animal
points(nuevos_datos[2, ], col="red", pch=11) # segundo animal
points(nuevos_datos[3, ], col="pink", pch=11) # tercer animal
plot(datos[ ,c(1,2)], col=datos$animal,
pch=19,
xlim=c(0, 180),
ylim=C(80,200))
#### Ahora vamos a predecir ####
predict(modelo_svm, newdata = nuevos_datos)
View(datos)
### Vamos a probar con nuevos datos
nuevos_datos <- data.frame(Height=c(67, 120, 100),
Weight=c(100, 190, 100)
)
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[ ,c(1,2)], col=datos$animal,
pch=19,
xlim=c(0, 180),
ylim=C(80,200))
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green",
lty=2)
# Vamos a agregar a la grafica los nuevos datos
# Para clasificarlos
points(nuevos_datos[1, ], col="green", pch=11) # primer animal
points(nuevos_datos[2, ], col="red", pch=11) # segundo animal
points(nuevos_datos[3, ], col="pink", pch=11) # tercer animal
#### Ahora vamos a predecir ####
predict(modelo_svm, newdata = nuevos_datos)
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[ ,c(1,2)], col=datos$animal,
pch=19,
xlim=c(0, 180),
ylim=C(80,200))
# Regeneramos grafica para actualizar los margenes x e y
# para poder visualizar los nuevos datos
plot(datos[ ,c(1,2)], col=datos$animal,
pch=19,
xlim=c(0, 180),
ylim=c(80,200))
abline(a= -b/w[1,2], b= -w[1,1]/w[1,2], col="green",
lty=2)
# Vamos a agregar a la grafica los nuevos datos
# Para clasificarlos
points(nuevos_datos[1, ], col="green", pch=11) # primer animal
points(nuevos_datos[2, ], col="red", pch=11) # segundo animal
points(nuevos_datos[3, ], col="pink", pch=11) # tercer animal
#### Ahora vamos a predecir ####
predict(modelo_svm, newdata = nuevos_datos)
abline(a = -b/w[1, 2], b = -w[1, 1]/w[1, 2],
col = "green", lty = 2)
# Crear un modelo de SVR para los datos del Titanic
table(datos$animal)
