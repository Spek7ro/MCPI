# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7941176
######## Ahora para VALIDACION K = 3 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7521008
DatosTitanic_SinLimpiar <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic_SinLimpiar)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
View(DatosTitanic_SinLimpiar)
View(DatosTitanic_SinLimpiar)
View(DatosTitanic_SinLimpiar)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# crear la particiones para TRAIN y TRAINING K = 3
indices = createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
# Validacion Cruzada K = 1
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
library(caret)
# Limpiar el dataset
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# Crear las particiones para K = 3
set.seed(123)
indices <- createFolds(y = datos_limpios$Vivio, k = 3, returnTrain = TRUE, list = TRUE)
# Función para calcular las métricas
calcular_metricas <- function(original, predicciones) {
cm <- table(Original = original, Prediccion = predicciones)
print(cm)
# Matriz de confusion
TN <- cm[1,1]
FP <- cm[1,2]
FN <- cm[2,1]
TP <- cm[2,2]
# Métricas
accuracy <- (TP + TN) / sum(cm)
sensibilidad <- TP / (TP + FN)
especificidad <- TN / (TN + FP)
return(list(Accuracy = accuracy,
Sensibilidad = sensibilidad,
Especificidad = especificidad))
}
# Validación cruzada para cada FOLD
for (i in 1:3) {
cat("\n================ FOLD", i, "================\n")
# Crear conjuntos de entrenamiento y prueba
datos_Fold_Entrenaminto <- datos_limpios[indices[[i]], ]
datos_Fold_Prueba <- datos_limpios[-indices[[i]], ]
# Entrenar el modelo
modeloX <- glm(Vivio ~ Sexo + Edad, data = datos_Fold_Entrenaminto, family = "binomial")
# ---- TRAIN ----
pred_train <- predict(modeloX, newdata = datos_Fold_Entrenaminto, type = "response")
pred_train_bin <- ifelse(pred_train >= 0.5, 1, 0)
metricas_train <- calcular_metricas(datos_Fold_Entrenaminto$Vivio, pred_train_bin)
cat("TRAIN:\n")
print(metricas_train)
# ---- TEST ----
pred_test <- predict(modeloX, newdata = datos_Fold_Prueba, type = "response")
pred_test_bin <- ifelse(pred_test >= 0.5, 1, 0)
metricas_test <- calcular_metricas(datos_Fold_Prueba$Vivio, pred_test_bin)
cat("TEST:\n")
print(metricas_test)
# ---- Guardar tablitas para Excel ----
tablita_train <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
PrediccionIA = pred_train_bin)
tablita_test <- data.frame(Original = datos_Fold_Prueba$Vivio,
PrediccionIA = pred_test_bin)
write.csv(tablita_train, paste0("Fold", i, "_Train.csv"), row.names = FALSE)
write.csv(tablita_test, paste0("Fold", i, "_Test.csv"), row.names = FALSE)
}
library(openxlsx)
install.packages("openxlsx")
library(openxlsx)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
library(caret)
library(openxlsx)
# Eliminar valores NA de Edad
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
# Crear particiones para K = 3
set.seed(123)
indices <- createFolds(y = datos_limpios$Vivio, k = 3, returnTrain = TRUE, list = TRUE)
# Función auxiliar para crear la tablita con TP, TN, FP, FN
crear_tablita <- function(original, prediccion) {
df <- data.frame(ValorOriginal = original, Predicciones = prediccion)
df$TP <- ifelse(df$ValorOriginal == 1 & df$Predicciones == 1, 1, 0)
df$TN <- ifelse(df$ValorOriginal == 0 & df$Predicciones == 0, 1, 0)
df$FP <- ifelse(df$ValorOriginal == 0 & df$Predicciones == 1, 1, 0)
df$FN <- ifelse(df$ValorOriginal == 1 & df$Predicciones == 0, 1, 0)
# Totales
TP <- sum(df$TP)
TN <- sum(df$TN)
FP <- sum(df$FP)
FN <- sum(df$FN)
sensibilidad <- round(TP / (TP + FN), 2)
especificidad <- round(TN / (TN + FP), 2)
# Fila de suma
fila_suma <- data.frame(ValorOriginal = "SUMA=", Predicciones = "",
TP = TP, TN = TN, FP = FP, FN = FN)
df_final <- rbind(df, fila_suma)
# Fila de métricas
fila_sens <- data.frame(ValorOriginal = "SENSITIVITY (TP/(TP+FN))", Predicciones = "",
TP = sensibilidad, TN = "", FP = "", FN = paste0(sensibilidad*100, "%"))
fila_esp <- data.frame(ValorOriginal = "SPECIFICITY (TN/(FP+TN))", Predicciones = "",
TP = especificidad, TN = "", FP = "", FN = paste0(especificidad*100, "%"))
df_final <- rbind(df_final, fila_sens, fila_esp)
return(df_final)
}
# Crear archivo Excel
wb <- createWorkbook()
# ---- Iterar por cada FOLD ----
for (i in 1:3) {
# Datos
datos_train <- datos_limpios[indices[[i]], ]
datos_test <- datos_limpios[-indices[[i]], ]
# Modelo
modelo <- glm(Vivio ~ Sexo + Edad, data = datos_train, family = "binomial")
# Predicciones binarizadas
pred_train <- ifelse(predict(modelo, newdata = datos_train, type = "response") >= 0.5, 1, 0)
pred_test <- ifelse(predict(modelo, newdata = datos_test, type = "response") >= 0.5, 1, 0)
# Crear tablitas
tablita_train <- crear_tablita(datos_train$Vivio, pred_train)
tablita_test <- crear_tablita(datos_test$Vivio, pred_test)
# Guardar cada una como hoja
addWorksheet(wb, paste0("Fold", i, "_TRAIN"))
addWorksheet(wb, paste0("Fold", i, "_TEST"))
writeData(wb, sheet = paste0("Fold", i, "_TRAIN"), tablita_train)
writeData(wb, sheet = paste0("Fold", i, "_TEST"), tablita_test)
}
# Guardar Excel final
saveWorkbook(wb, "Resultados_Titanic_Folds.xlsx", overwrite = TRUE)
DatosTitanic <- read.csv("D:/MCPI/Análisis_De_Datos/AnalisisDeDatos_Project/Datasets/DatosTitanic_SinLimpiar.csv", stringsAsFactors=TRUE)
View(DatosTitanic)
# Libreria Para la validacion cruzada
library(caret)
sum(is.na(DatosTitanic$Id))
sum(is.na(DatosTitanic$Vivio))
sum(is.na(DatosTitanic$Pclase))
sum(is.na(DatosTitanic$Nombre))
sum(is.na(DatosTitanic$Sexo))
sum(is.na(DatosTitanic$Edad)) # 177 datos NA`S
# En este caso quitaremos el 20% de los datos vamos a remover 177 datos
datos_limpios <- DatosTitanic[!is.na(DatosTitanic$Edad), ]
indices = createFolds(y = datos_limpios$Vivio, k = 3,
returnTrain = TRUE,
list = TRUE)
# Validacion Cruzada K = 1
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < 0.5] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= 0.5] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7605042
library(pROC)
mi_curvaz <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels = c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
mi_curvaz <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
### Area bajo la curva
mi_curva$auc
mi_curva
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret="threshold")
valores$threshold
mi_curva
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
### Area bajo la curva
mi_curva$auc # 0.7932 AUC
mi_curva
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.789916
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
#### Calcular Curva ROC
library(pROC)
### Area bajo la curva
mi_curva$auc # 0.7932 AUC
mi_curva
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores$threshold
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC")
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.8067227
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba")
### Area bajo la curva
mi_curva$auc # 0.7932 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7605042
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba K=1")
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba K=1")
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC -  Entrenaminto K=1")
### Area bajo la curva
mi_curva$auc # 0.7932 AUC
mi_curva
### Area bajo la curva
mi_curva$auc # 0.7932 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.8067227
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
###### Validacion Cruzada K = 1 #######
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold1, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold1, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC -  Entrenaminto K=1")
### Area bajo la curva
mi_curva$auc # 0.7623 AUC
mi_curva
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7815126
######## Ahora para VALIDACION K = 1 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba K=1")
### Area bajo la curva
mi_curva$auc # 0.7938 AUC
mi_curva
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.8109244
##########################
# Validacion Cruzada K = 2
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold2, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold2, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC - Entrenamiento K=2")
### Area bajo la curva
mi_curva$auc # 0.7938 AUC
mi_curva
### Area bajo la curva
mi_curva$auc # 0.7938 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7941176
######## Ahora para VALIDACION K = 2 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba K=2")
### Area bajo la curva
mi_curva$auc # 0.7938 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7521008
######################
# Validacion Cruzada K = 3
datos_Fold_Entrenaminto <- datos_limpios[indices$Fold3, ]
datos_Fold_Prueba <- datos_limpios[-indices$Fold3, ] # todos menos los del los inices
##### ----- Entrenamintos Modelos ------ #####
modeloX <- glm(Vivio ~ Sexo + Edad,
data = datos_Fold_Entrenaminto,
family = "binomial")
# Metricas Entrenaminto
predicciones <- predict(modeloX, newdata = datos_Fold_Entrenaminto,
type = "response")
# Construir la tabla
tablitaX <- data.frame(Original = datos_Fold_Entrenaminto$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='red', main="Grafica ROC - Entrenamiento K=3")
### Area bajo la curva
mi_curva$auc # 0.7962 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
# Binarizar pero de forma vectorial:
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
# Calcular el accuracy de entrenaminto
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.7563025
View(valores)
######## Ahora para VALIDACION K = 3 ########
predicciones <- predict(modeloX, newdata = datos_Fold_Prueba,
type = "response")
tablitaX <- data.frame(Original = datos_Fold_Prueba$Vivio,
prediccionesModelo = predicciones)
#### Calcular Curva ROC
library(pROC)
mi_curva <- roc(tablitaX$Original, tablitaX$prediccionesModelo,
levels=c(0,1), plot=TRUE, ci=TRUE,
smooth=FALSE, direction='auto',
col='green', main="Grafica ROC - Prueba K=3")
### Area bajo la curva
mi_curva$auc # 0.7581 AUC
#### Obtenemos los valores de Threshold (umbral binarizacion)
valores <- coords(mi_curva, "best", ret=c("threshold", "specificity", "sensitivity"))
valores
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo < valores$threshold] <- 0
tablitaX$prediccionesModelo[tablitaX$prediccionesModelo >= valores$threshold] <- 1
accuracy <- sum(tablitaX$Original == tablitaX$prediccionesModelo)/nrow(tablitaX)
accuracy # 0.8277311
